{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2# Projet numérique III : câble sous-marin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Louis Blazejczak, Emmanuel Gardin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions théoriques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.\n",
    "La loi forte des grands nombres nous autorise à estimer l'espérance conditionnelle par la moyenne empirique de simulations conditionnelles. \n",
    "\n",
    "#### 2.\n",
    "\n",
    "On considère le vecteur gaussien $Z_{1} = (Z(x_{j1}), Z(x_{j2}), ..., Z(x_{jn}))$ et le vecteur $Z_{2}$ des composantes de $Z$ qui ne sont pas connues. On réordonne $Z$ de manière à ce que les termes de $Z1$ soient les n derniers termes de Z.\n",
    "On note $C$ la matrice de covariance définie positive de $Z$.\n",
    "$C$ peut se décomposer en blocs :\n",
    "\\begin{align}\n",
    "C  = \n",
    "\\begin{pmatrix} \n",
    "C_{Z_{2}} & C_{Z_{2},Z_{1}} \\\\ C_{Z_{1},Z_{2}} & C_{Z_{1}}\n",
    "\\end{pmatrix}\n",
    "\\end{align}\n",
    "\n",
    "La loi conditionnelle du vecteur des composantes de  $Z$ correspondant aux points de discrétisation sans observation connaissant les valeurs prises par les composantes aux sites d'observation s'écrit alors :\n",
    "\n",
    "\n",
    "$f_{Z_{2}|Z_{1} = z_{1}}(z_{2}) = \\frac{1}{(2 \\pi)^{n/2} \\sqrt{det(CS_{Z_{2}})}}exp(- \\frac{1}{2}(z_{2}- \\Psi(z_1))^{t}CS_{Z_{2}}^{-1}(z_{2}- \\Psi(z_1)))$\n",
    "\n",
    "où $CS_{Z_{2}}$ est le complément de Schur du bloc $C_{Z_{2}}$ : $CS_{Z_{2}} = C_{Z_{2}} - C_{Z_{2},Z_{1}}C_{Z_{1}}^{-1}C_{Z_{1},Z_{2}}$ et $\\Psi$ est l'espérance conditionnelle du vecteur des sites sans observation $Z_{2}$ sachant $Z_{1}$\n",
    "\n",
    "#### 3.\n",
    "\n",
    "Soit $Y = (Y_{1}, ..., Y_{p})$ un vecteur de composantes gaussiennes indépendantes, toutes d'espérance nulle et de variance 1. $Z = m + RY$ où $R$ est une matrice $p \\times p$ et $m$ est un vecteur de taille $p$.\n",
    "Alors $Z$ est gaussien, comme combinaison linéaire de variables gaussiennes, $E(Z) = E(m + RY) = m$ et $V(Z) = E((RY)^{2}) = RI_{p}R^{t} = RR^{t}$. On note $C = RR^{t}$.\n",
    "\n",
    "La loi $f_{Z}$ de $Z$ est alors :\n",
    "\n",
    "\\begin{equation}\n",
    "f_{Z}(z) = \\frac{1}{(2 \\pi)^{p/2} \\sqrt{det(C)}}exp(- \\frac{1}{2}(z-m)^{t}C^{-1}(x-m))\n",
    "\\end{equation}\n",
    "\n",
    "#### 4.\n",
    "\n",
    "On souhaite simuler un vecteur gaussien $Z = (Z(x_{0}), ..., Z(x_{N}))$ à valeurs dans ${\\rm I\\!R}^N$, d'espérance m et de matrice de covariance C définie positive données.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implémentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des dépendances\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Discrétisation\n",
    "\n",
    "A = 0\n",
    "B = 500\n",
    "N = 101\n",
    "Delta = (B-A)/(N-1)\n",
    "discretization_indexes = np.arange(N)\n",
    "discretization = discretization_indexes*Delta\n",
    "\n",
    "#Paramètres du modèle\n",
    "\n",
    "mu = -5\n",
    "a = 50\n",
    "sigma2 = 12\n",
    "\n",
    "# Données\n",
    "\n",
    "observation_indexes = [0, 20, 40, 60, 80, 100]\n",
    "depth = np.array([0, -4, -12.8, -1, -6.5, 0])\n",
    "\n",
    "# Indices des composantes correspondant aux observations et aux composantes non observées\n",
    "\n",
    "unknown_indexes = list(set(discretization_indexes)-set(observation_indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cov(distance, a, sigma2):\n",
    "    covariance = np.zeros((101, 101))\n",
    "    for i in range(0, len(covariance)):\n",
    "        for j in range(0, len(covariance[0])):\n",
    "            covariance[i][j] = sigma2*math.exp(-abs(distance[i][j])/a)\n",
    "    return covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = np.zeros((101, 101))\n",
    "for i in range(0, 101):\n",
    "    for j in range(0, 101):\n",
    "        distance[i][j] = abs((i-j)*Delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.20000000e+01 1.08580490e+01 9.82476904e+00 ... 6.65419193e-04\n",
      "  6.02096185e-04 5.44799157e-04]\n",
      " [1.08580490e+01 1.20000000e+01 1.08580490e+01 ... 7.35401941e-04\n",
      "  6.65419193e-04 6.02096185e-04]\n",
      " [9.82476904e+00 1.08580490e+01 1.20000000e+01 ... 8.12744838e-04\n",
      "  7.35401941e-04 6.65419193e-04]\n",
      " ...\n",
      " [6.65419193e-04 7.35401941e-04 8.12744838e-04 ... 1.20000000e+01\n",
      "  1.08580490e+01 9.82476904e+00]\n",
      " [6.02096185e-04 6.65419193e-04 7.35401941e-04 ... 1.08580490e+01\n",
      "  1.20000000e+01 1.08580490e+01]\n",
      " [5.44799157e-04 6.02096185e-04 6.65419193e-04 ... 9.82476904e+00\n",
      "  1.08580490e+01 1.20000000e+01]]\n"
     ]
    }
   ],
   "source": [
    "C = cov(distance, a, sigma2)\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_Z1, distanceZ1 = np.zeros((len(observation_indexes),len(observation_indexes)))\n",
    "C_Z2, distanceZ2 = np.zeros((len(unknown_indexes),len(unknown_indexes)))\n",
    "C_Z1_Z2, distanceZ1_Z2 = np.zeros((len(observation_indexes),len(unknown_indexes)))\n",
    "\n",
    "for i in range(len(observation_indexes)):\n",
    "    for j in range(len(observarion_indexes)):\n",
    "        C_Z1[i][j] = C[observation_indexes[i]][observation_indexes[j]]\n",
    "\n",
    "for i in range(len(observation_indexes)):\n",
    "    for j in range(len(unknown_indexes)):\n",
    "        C_Z1_Z2[i][j] = C[observation_indexes[i]][unknown_indexes[j]]\n",
    "        \n",
    "for i in range(len(unknown_indexes)):\n",
    "    for j in range(len(unknown_indexes)):\n",
    "        C_Z2[i][j] = C[unknown_indexes[i]][unknown_indexes[j]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-28-85e6c2da9fcc>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-28-85e6c2da9fcc>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    my =\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "my = \n",
    "mz = \n",
    "Esp_Z2sachantZ1 = (my - np.dot(C_Z1_Z2,C_Z)*(Z-mz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Probablement 14 et 15\n",
    "#To do : Questions 5,6,7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def longeur(Z, Delta):\n",
    "    length = 0\n",
    "    for i in range(len(Z)-1):\n",
    "        length += math.sqrt(Delta^2+(Z[i+1]-Z[i])^2)\n",
    "    return length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
